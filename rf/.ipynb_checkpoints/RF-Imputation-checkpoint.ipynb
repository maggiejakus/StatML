{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in files\n",
    "#already been split into training people and testing groups\n",
    "#made from impute2\n",
    "\n",
    "testing_SNPs = pd.read_csv('testing.txt', delimiter=' ', header = None)\n",
    "training_SNPs = pd.read_csv('training.txt', delimiter = ' ', header = None)\n",
    "#map22 = pd.read_csv('map22.txt', delimiter = '\\t', header = None)\n",
    "map22_2 = pd.read_csv('chr22.txt', delimiter = ' ', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 505)\n",
      "2488\n",
      "2488\n"
     ]
    }
   ],
   "source": [
    "#read in map\n",
    "#find how many SNPs in our training/testing SNPs (they're the same...) are also in our map\n",
    "\n",
    "print(training_SNPs.shape) #we only have 250 people in our training data\n",
    "#print(map22[:6][0]) #first col is physical position, second is recombination rate with the next SNP, \\\n",
    "#third is genetic map in cM\n",
    "\n",
    "training_SNPs_arr = training_SNPs[:][2].to_numpy()\n",
    "testing_SNPs_arr = testing_SNPs[:][2].to_numpy()\n",
    "\n",
    "#map22_arr_pos = map22.loc[:][0].to_numpy()\n",
    "\n",
    "#this map has more data in it\n",
    "chr22_arr = map22_2.loc[:][1].to_numpy()\n",
    "\n",
    "indices_train = np.where(np.in1d(chr22_arr, training_SNPs_arr))\n",
    "print(len(indices_train[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(training_SNPs[:][2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people 253\n"
     ]
    }
   ],
   "source": [
    "#convert testing file into 3 part prob dist file\n",
    "#for each SNP, each person, who is 100% AA, AB, or BB, which is written as 00, 01, or 11, gets \n",
    "#turned into one number for AA, one number for AB, one number for BB (so 1, 0,0 as AA, 0, 1, 0 as\n",
    "#AB, and 0,0,1 for BB)\n",
    "\n",
    "\n",
    "SNPs = int(testing_SNPs.shape[0])\n",
    "people = int((testing_SNPs.shape[1]-5) / 2.0)\n",
    "\n",
    "testing_dist = np.zeros((SNPs, people * 3))\n",
    "maj_homozygous_test = np.zeros((SNPs, people))\n",
    "heterozygous_test = np.zeros((SNPs, people))\n",
    "min_homozygous_test = np.zeros((SNPs, people))\n",
    "\n",
    "#need to come back to this...\n",
    "for SNP in range(SNPs):\n",
    "    for person in range(people):\n",
    "        if testing_SNPs.loc[SNP, 5 + person*2] == 0 & testing_SNPs.loc[SNP, 6 + person*2] == 0:\n",
    "            testing_dist[SNP, 3*person] = 1\n",
    "            testing_dist[SNP, 3*person + 1] = 0\n",
    "            testing_dist[SNP, 3*person + 2] = 0\n",
    "            maj_homozygous_test[SNP, person] = 1\n",
    "        elif testing_SNPs.loc[SNP, 5 + person*2] == 1 & testing_SNPs.loc[SNP, 6 + person*2] == 0:\n",
    "            testing_dist[SNP, 3*person] = 0\n",
    "            testing_dist[SNP, 3*person + 1] = 1\n",
    "            testing_dist[SNP, 3*person + 2] = 0\n",
    "            heterozygous_test[SNP, person] = 1\n",
    "        elif testing_SNPs.loc[SNP, 5 + person*2] == 0 & testing_SNPs.loc[SNP, 6 + person*2] == 1:\n",
    "            testing_dist[SNP, 3*person] = 0\n",
    "            testing_dist[SNP, 3*person + 1] = 1\n",
    "            testing_dist[SNP, 3*person + 2] = 0\n",
    "            heterozygous_test[SNP, person] = 1\n",
    "        elif testing_SNPs.loc[SNP, 5 + person*2] == 1 & testing_SNPs.loc[SNP, 6 + person*2] == 1:\n",
    "            testing_dist[SNP, 3*person] = 0\n",
    "            testing_dist[SNP, 3*person + 1] = 0\n",
    "            testing_dist[SNP, 3*person + 2] = 1\n",
    "            min_homozygous_test[SNP, person] = 1\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 505)\n"
     ]
    }
   ],
   "source": [
    "print(training_SNPs.shape)\n",
    "training_SNPs = training_SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert training file into 3 part prob dist file\n",
    "#for each SNP, each person, who is 100% AA, AB, or BB, which is written as 00, 01, or 11, gets \n",
    "#turned into one number for AA, one number for AB, one number for BB (so 1, 0,0 as AA, 0, 1, 0 as\n",
    "#AB, and 0,0,1 for BB)\n",
    "\n",
    "SNPs = int(training_SNPs.shape[0])\n",
    "people_training = int((training_SNPs.shape[1]-5) / 2.0)\n",
    "\n",
    "training_dist = np.zeros((SNPs, people_training * 3))\n",
    "maj_homozygous_train = np.zeros((SNPs, people_training))\n",
    "heterozygous_train = np.zeros((SNPs, people_training))\n",
    "min_homozygous_train = np.zeros((SNPs, people_training))\n",
    "\n",
    "#need to come back to this...\n",
    "for SNP in range(SNPs):\n",
    "    for person in range(people_training):\n",
    "        if training_SNPs.loc[SNP, 5 + person*2] == 0 & training_SNPs.loc[SNP, 6 + person*2] == 0:\n",
    "            training_dist[SNP, 3*person] = 1\n",
    "            training_dist[SNP, 3*person + 1] = 0\n",
    "            training_dist[SNP, 3*person + 2] = 0\n",
    "            maj_homozygous_train[SNP, person] = 1\n",
    "        elif training_SNPs.loc[SNP, 5 + person*2] == 1 & training_SNPs.loc[SNP, 6 + person*2] == 0:\n",
    "            training_dist[SNP, 3*person] = 0\n",
    "            training_dist[SNP, 3*person + 1] = 1\n",
    "            training_dist[SNP, 3*person + 2] = 0\n",
    "            heterozygous_train[SNP, person] = 1\n",
    "        elif training_SNPs.loc[SNP, 5 + person*2] == 0 & training_SNPs.loc[SNP, 6 + person*2] == 1:\n",
    "            training_dist[SNP, 3*person] = 0\n",
    "            training_dist[SNP, 3*person + 1] = 1\n",
    "            training_dist[SNP, 3*person + 2] = 0\n",
    "            heterozygous_train[SNP, person] = 1\n",
    "        elif training_SNPs.loc[SNP, 5 + person*2] == 1 & training_SNPs.loc[SNP, 6 + person*2] == 1:\n",
    "            training_dist[SNP, 3*person] = 0\n",
    "            training_dist[SNP, 3*person + 1] = 0\n",
    "            training_dist[SNP, 3*person + 2] = 1\n",
    "            min_homozygous_train[SNP, person] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=4, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=200, n_jobs=None, oob_score=False,\n",
       "                       random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transpose the matrices so they are people # rows and SNP # columns\n",
    "\n",
    "maj_homozygous_train.transpose()\n",
    "heterozygous_train.transpose()\n",
    "min_homozygous_train.transpose()\n",
    "\n",
    "#generate training data + labels for very first SNP\n",
    "idx_snp = 100\n",
    "offset = 20\n",
    "\n",
    "label_maj_homo = maj_homozygous_train[:, idx_snp]\n",
    "training_maj_homo = np.hstack((maj_homozygous_train[:, (idx_snp - 20):idx_snp], maj_homozygous_train[:, (idx_snp + 1):(idx_snp + 1 + offset)]))\n",
    "\n",
    "snp100 = RandomForestClassifier(n_estimators = 200, max_depth=4, class_weight = \"balanced\")\n",
    "snp100.fit(training_maj_homo, label_maj_homo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.784\n",
      "predicted 823.0\n",
      "actual values 601.0\n"
     ]
    }
   ],
   "source": [
    "maj_homozygous_test.transpose()\n",
    "heterozygous_test.transpose()\n",
    "min_homozygous_test.transpose()\n",
    "\n",
    "label_maj_homo_test = maj_homozygous_test[:, idx_snp]\n",
    "testing_maj_homo = np.hstack((maj_homozygous_test[:, (idx_snp - 20):idx_snp], maj_homozygous_train[:, (idx_snp + 1):(idx_snp + 1 + offset)]))\n",
    "predict_label_maj_100 = snp100.predict(testing_maj_homo)\n",
    "\n",
    "print(np.sum(predict_label_maj_100 == label_maj_homo_test)/len(label_maj_homo_test))\n",
    "print(\"predicted\", np.sum(predict_label_maj_100))\n",
    "print(\"actual values\", np.sum(label_maj_homo_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(5000, 253)\n"
     ]
    }
   ],
   "source": [
    "print(type(min_homozygous))\n",
    "print(min_homozygous.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "(5000, 253)\n"
     ]
    }
   ],
   "source": [
    "#calculate indices for imputing\n",
    "'''\n",
    "thin_var = 0.5\n",
    "np.random.seed(0)\n",
    "\n",
    "idx_imputing = np.random.choice(int(len(maj_homozygous)), int(len(maj_homozygous) * thin_var), replace = False)\n",
    "sorted_idx = np.sort(idx_imputing)\n",
    "\n",
    "print(people)\n",
    "print(maj_homozygous.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "#actually remove indices of interest\n",
    "\n",
    "maj_homoz_toImpute = np.zeros((SNPs, people))\n",
    "hetero_toImpute = np.zeros((SNPs, people))\n",
    "min_homoz_toImpute = np.zeros((SNPs, people))\n",
    "\n",
    "#not sure if there's any point to \n",
    "maj_homoz_labels = np.zeros((int(len(maj_homozygous) * thin_var), 2))\n",
    "\n",
    "for SNP in range(SNPs):\n",
    "    if SNP in sorted_idx:\n",
    "        maj_homoz_toImpute[SNP] = maj_homozygous[SNP]\n",
    "    else:\n",
    "        maj_homoz_toImpute[SNP] = 2 #2 would mean it's to be imputed\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create \"labels\" vector for training\n",
    "#starting with major homozygous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the RF model will produce the \"labels\" vector (testing)\n",
    "#starting with major homozygous \n",
    "#need to create the data matrix\n",
    "\n",
    "testing_data = np.zeros((int(len(maj_homozygous) * thin_var) * people , 20))\n",
    "counter = 1\n",
    "\n",
    "for SNP in range(SNPs):\n",
    "    if SNP in sorted_idx:\n",
    "        #do nothing\n",
    "    else:\n",
    "        if SNP < 10 or SNP > (SNPs - 11): \n",
    "        else:\n",
    "            for person in people:\n",
    "                for i in range(10):\n",
    "                    testing_data[person*counter, i] = \n",
    "\n",
    "\n",
    "#for SNP in range(int(len(maj_homozygous) * thin_var)): #2500\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
